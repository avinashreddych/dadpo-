{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "full_dataset_train = load_dataset(\"PKU-Alignment/PKU-SafeRLHF\", split=\"train\")\n",
    "\n",
    "full_dataset_test = load_dataset(\"PKU-Alignment/PKU-SafeRLHF\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_dataset(dataset: Dataset):\n",
    "    df = dataset.to_pandas()\n",
    "    tdf_0 = df[[\"prompt\", \"response_0\"]]\n",
    "    tdf_0 = tdf_0.rename(columns={\"response_0\": \"response\"})\n",
    "    tdf_1 = df[[\"prompt\", \"response_1\"]]\n",
    "    tdf_1 = tdf_1.rename(columns={\"response_1\": \"response\"})\n",
    "    tdf = pd.concat([tdf_0, tdf_1], axis=0)\n",
    "    return tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = create_pretrain_dataset(full_dataset_train)\n",
    "test_df = create_pretrain_dataset(full_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv(\"train_data_pku_30k.csv\", index=False)\n",
    "# test_df.to_csv(\"test_data_pku_30k.csv\", index=False)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", trust_remote_code=True)\n",
    "\n",
    "\n",
    "def prepare_sample_text(prompt, response):\n",
    "    \"\"\"Prepare the text from a sample of the dataset.\"\"\"\n",
    "    text = f\"Question: {prompt}\\n\\nAnswer: {response}\"\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_num_tokens(sample):\n",
    "    txt = prepare_sample_text(sample[\"prompt\"], sample[\"response\"])\n",
    "    tokens = tokenizer(txt, return_tensors=\"pt\")\n",
    "    return {\"len_of_input\": tokens[\"input_ids\"].shape[1]}\n",
    "\n",
    "def less_than_256(sample):\n",
    "    return sample[\"len_of_input\"] < 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2e090c3b6d4558bc76affe8c252a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/594788 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982df68d6dc844e286df2983fc16e5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/66088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3991114e30b04d0ba5a485387712f30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/594788 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59a7c42b1d64c5fb4d4e0f2fc5f98f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/66088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(get_num_tokens, batched=False)\n",
    "test_dataset = test_dataset.map(get_num_tokens, batched=False)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.filter(less_than_256)\n",
    "test_dataset = test_dataset.filter(less_than_256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_pandas().to_csv(\"train_data_pku.csv\", index = False)\n",
    "test_dataset.to_pandas().to_csv(\"test_data_pku.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_fields(prompt_fields, state=False):\n",
    "    fields_without_prompt = {}\n",
    "    num_fields = 0\n",
    "    # loop over all the keys\n",
    "    print(\"prompt_fields: \", prompt_fields)\n",
    "    for key, value in prompt_fields.items():\n",
    "        print(\"key: \", key)\n",
    "        print(\"value: \", value)\n",
    "        if type(value) == dict:\n",
    "            fields, num = get_prompt_fields(value)\n",
    "            fields_without_prompt[key] = fields\n",
    "            num_fields += num\n",
    "        elif type(value) == list:\n",
    "            fields_without_prompt[key] = []\n",
    "            for each_field in value:\n",
    "                fields, num = get_prompt_fields(each_field)\n",
    "                fields_without_prompt[key].append(fields)\n",
    "                num_fields += num\n",
    "        # check if the value is leaf dict ({\"value\": <str>, \"line_num\": <str>} or {\"prompt\": <str>})\n",
    "        else:\n",
    "            return state, 1\n",
    "    return fields_without_prompt, num_fields"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
